{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Data-Centric AI, MIT IAP 2023."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 1: Data-Centric AI vs. Model-Centric AI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is not data centric AI:\n",
    "\n",
    "Examples:\n",
    "\n",
    "1. Hand-picking a bunch of data points you think will improve the model.\n",
    "2. Double the size of your dataset and train an improved model on more data.\n",
    "\n",
    "Data centric version:\n",
    "\n",
    "Examples:\n",
    "\n",
    "1. Coreset selection: coreset selection in supervised learning is to produce a weighted subset of data, so that training only on the subset achieves similar performance as training on the entire dataset ***Look for testing it***.\n",
    "\n",
    "2. Dataset augmentation.\n",
    "3. outlier detection and removal.\n",
    "4. Feature selection.\n",
    "5. Establishing consensus labels.\n",
    "6. active learning (selecting the most informative data to label next).\n",
    "7. curriculum learning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 2: Label Errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding label erros by sorting data by loss**\n",
    "\n",
    "- how much error is in the dataset.\n",
    "- then, define which labels have more error. sort!\n",
    "- whats the cutt-off?.\n",
    "\n",
    "**What is confident learning**\n",
    "\n",
    "Confident learning is a framework of theory and algorithms for:\n",
    "\n",
    "- Finding label erros in a dataset.\n",
    "- Ranking data by likehood of being a label issue.\n",
    "- Learning with noise labels.\n",
    "- ***Complete characterization of label noise in a dataset*** (focus here!!).\n",
    "\n",
    "key idea:\n",
    "\n",
    "    With confident learning, any models predicted probabilities to find label errors. (data centric, model agnostic)\n",
    "\n",
    "**Where do noise labels come from??**\n",
    "\n",
    "- clicked the wrong bottom.\n",
    "- mistakes.\n",
    "- mismeasurement.\n",
    "- incompetence.\n",
    "- another ml model's bad predictions.\n",
    "\n",
    "All of these results in label flippigns.\n",
    "\n",
    "Example of label flippings:\n",
    "\n",
    "- Image of a Dog is labeled in fox.\n",
    "- Tweet \"Hi Welcome to the team\" is labeled toxic language.\n",
    "\n",
    "**How noise labels are generated**\n",
    "\n",
    "- uniform/symmetric class-conditional label noise.\n",
    "- systematic/assymetric class-conditional label noise.\n",
    "- instance-dependent label noise.\n",
    "\n",
    "**What's uncertainty**\n",
    "\n",
    "Its the opposite of confidence (lack of confidence). Depends on:\n",
    "\n",
    "- the difficult of an example (aletoric - label noise: labels have been flipped to another class).\n",
    "- missunderstaing the example (epistemic - model noise: erroneus predicted probabilities).\n",
    "\n",
    "**CL assumes class-conditional label noise**\n",
    "\n",
    "We assume labels are flipped based on an unknown transition matrix P(y~|y*) that depends only on pairwase noise rates between classes, not the data `x`. The `class conditional` label noise depends on the class, not the data.\n",
    "\n",
    "`Deep learning is robust to label noise`. These results assume uniformly random label noise and usually don't apply to real world seetings.\n",
    "\n",
    "**How does confident learning work**\n",
    "\n",
    "Directly estimate the joint distribution of observed noise labels and latent true labels.\n",
    "\n",
    "__key_idea__: First we find the threshold as a proxy for the machine's self confidence, on average, for each task/class j (you can apply cross-validation to get out-of-sample predicted probabilities. Then average the preidcted probabilities by class).\n",
    "\n",
    "$$\n",
    "  t_{j} = \\frac{1}{|X_{\\hat{y}=j}|} \\sum_{x \\in X_{\\hat{y}=j}} \\mathbb P(\\hat{y}=j; x; O)\n",
    "$$\n",
    "\n",
    "```python\n",
    "\n",
    "from  cleanlab.filters import find_label_issues\n",
    "\n",
    "#! Works with any ml model -  just input the model's predicted probabilities\n",
    "\n",
    "ordered_label_issues = find_label_issues(\n",
    "  labels=labels,\n",
    "  pred_probs=pred_probs, # out-of-sample predicted probabilities from any model\n",
    "  return_indices_ranked_by='self_confidence'\n",
    ")\n",
    "```\n",
    "\n",
    "**Ranking label errors**\n",
    "\n",
    "Self confidence.\n",
    "\n",
    "$$\n",
    "  \\mathbb P(\\hat{y}=i; x)\n",
    "$$\n",
    "\n",
    "Normalized margin (with formula). Then, sort it!!\n",
    "\n",
    "$$\n",
    "  \\mathbb P(\\hat{y} = i) - \\max_{i \\in m}(\\mathbb P(\\hat{y}))\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 3: Dataset Creation and Curation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concerns when sourcing the data**\n",
    "\n",
    "Key questions when sourcing training data\n",
    "\n",
    "1. How will the resulting ml model be used?\n",
    "    - On what population will model be making predictions and when.\n",
    "\n",
    "2. Hypothetical edge cases where we need model make right predictions.\n",
    "    - High stakes scenarios, rare events.\n",
    "\n",
    "sparse correlation: Ml Model = shortcut cheaters.\n",
    "\n",
    "selection bias: training delta distribution != distribbution in deployment.\n",
    "\n",
    "causes:\n",
    "\n",
    "    - time.\n",
    "    - overfitting.\n",
    "    - rare events.\n",
    "    - Convenience.\n",
    "    - Location.\n",
    "\n",
    "`Validation data` should be similar to distribution in deployment (use most recent data).\n",
    "\n",
    "__How much data should be collected??__\n",
    "\n",
    "Goal: 95% accuracy.\n",
    "\n",
    "One idea: plot (x: size data, y: accuracy; labels: every algo to validate).\n",
    "\n",
    "**Concerns when sourcing the label**\n",
    "\n",
    "play with annotators (Data Annotation).\n",
    "\n",
    "problems:\n",
    "\n",
    "1.  Low accuracy annotators.\n",
    "2. Copycat\n",
    "\n",
    "https://newscatcherapi.com/blog/top-6-text-annotation-tools\n",
    "\n",
    "Multi-annotator estimate:\n",
    "\n",
    "- Consensus label = single best label (Simple majority vote - confidence score).\n",
    "- confidence in consensus = how likely is it wrong.\n",
    "- quality of annotator = overall accuracy of their labels.\n",
    "\n",
    "Better methodology: CrowdLab (it should converge with model performance - it could be bat if your model is poorly accurate. take care of it!)\n",
    "\n",
    "https://cleanlab.ai/blog/multiannotator/\n",
    "\n",
    "__Textbook__: Human-in-the-loop Machine Learning (Robert Monarch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
